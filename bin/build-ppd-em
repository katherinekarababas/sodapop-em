#!/usr/bin/env python

'BUILD-PPD -- build posterior predictive distribution from posterior population distribution'
__usage__ = 'build-ppd pop_params_post.csv [-p pop_model1 -o /path/to/output.csv -s num_samps -v]'
__author__ = 'Philippe Landry (pgjlandry@gmail.com)'
__date__ = '01-2021'

from argparse import ArgumentParser
import numpy as np
import numpy.random
import os
import astropy.units as u
from astropy.coordinates import Distance
from astropy.cosmology import Planck15 as cosmo
import sodapop.populations as pop
import sodapop.parameters as prm
import sodapop.priors as pri
import sodapop.diagnostics as dgn
import sodapop.select as sel

parser = ArgumentParser(description=__doc__)
parser.add_argument('popparams')
parser.add_argument('-p', '--popmod', help='name of population model, DEFAULT="unif_m1m2"', default="unif_m1m2")
parser.add_argument('-s', '--nsel', help='number of samples to use for integrating ppd, DEFAULT=5000', default=5e3)
parser.add_argument('-m', '--maxsamps', help='maximum number of population samples to use in marginalization, DEFAULT=10000', default=1e4)
parser.add_argument('-f', '--selfunc', help='name of selection function, DEFAULT=False', default=False)
parser.add_argument('-o', '--outpath', help='path for output ppd file, DEFAULT=AUTO', default=False)
parser.add_argument('-d', '--delim', help='delimiter for data file, DEFAULT=","', default=',')
parser.add_argument('-t', '--type', help='type of ppd to plot, DEFAULT=mean', default='mean')
parser.add_argument('-v', '--verbose', action='store_true', default=False)
args = parser.parse_args()

###

if args.outpath: out_path = args.outpath
else: out_path = os.path.dirname(args.popparams)+'/'+args.popmod+'_ppd.csv'

if args.type == 'mean': ppd_type = False
elif args.type == 'med': ppd_type = True

N_SAMP = int(args.nsel)
MAX_SAMPS = int(args.maxsamps)

MMIN, MMAX = (0.5,3.5)
mgrid = np.arange(MMIN,MMAX,0.01)
msamps = np.random.uniform(MMIN,MMAX,N_SAMP)

FIXED_DL = 100.
FIXED_Z = Distance(FIXED_DL,unit=u.Mpc).compute_z(cosmology=cosmo)

WT_COLS = ['log_like', 'log_detfrac', 'weight']

CL = 0.9 # confidence level for ppd error envelope

###

# get population model and store population parameters in a dictionary

pop_model = pop.get_pop_prior(args.popmod)

pop_param_names = (pop.get_pop_params(args.popmod)).split(',') 
lambda_dict = prm.create_lambda_dict(pop_param_names)
	
# load population posterior

pop_params = np.genfromtxt(args.popparams, names=True, dtype=None, delimiter=args.delim, encoding=None)
param_names = list(pop_params.dtype.names)
for wt_col in WT_COLS: param_names.remove(wt_col)
num_post_samps = len(pop_params[param_names[0]])

# load selection function

if args.selfunc == False or args.selfunc == 'False': select_func = lambda *x : 1.
else: select_func = sel.get_select_func(args.selfunc)

# marginalize over population realizations

lambdas = [[lambda_dict[param](pop_params[line]) for param in pop_param_names if param in param_names] for line in range(num_post_samps)]

if len(lambdas) > MAX_SAMPS:
	idxs = np.random.choice(range(num_post_samps),MAX_SAMPS,False)
	lambdas = np.array(lambdas)[idxs]
	lambdas = list(lambdas)
	num_post_samps = MAX_SAMPS

padm, ppdm = [], []
padm_med, ppdm_med = [], []
padm_lb, ppdm_lb = [], []
padm_ub, ppdm_ub = [], []

for m in mgrid:

	counts_per_model, obs_counts_per_model = [], []

	for lambdaa in lambdas:
	
		model_counts = pop_model(m,lambdaa)
		model_select = select_func(m,FIXED_DL,FIXED_Z)
		model_obs = model_counts*model_select
		
		counts_per_model += [model_counts]
		obs_counts_per_model += [model_obs]
		
	avg_counts = np.sum(counts_per_model)/num_post_samps
	avg_obs_counts = np.sum(obs_counts_per_model)/num_post_samps
	
	med_counts = np.median(counts_per_model)
	med_obs_counts = np.median(obs_counts_per_model)
	
	lb_counts = np.quantile(counts_per_model,(1.-CL)/2.)
	lb_obs_counts = np.quantile(obs_counts_per_model,(1.-CL)/2.)
	
	ub_counts = np.quantile(counts_per_model,CL+(1.-CL)/2.)
	ub_obs_counts = np.quantile(obs_counts_per_model,CL+(1.-CL)/2.)
	
	padm += [avg_counts]
	ppdm += [avg_obs_counts]
	
	padm_med += [med_counts]
	ppdm_med += [med_obs_counts]
	
	padm_lb += [lb_counts]
	ppdm_lb += [lb_obs_counts]
	
	padm_ub += [ub_counts]
	ppdm_ub += [ub_obs_counts]

norm_pad = np.trapz(padm,mgrid)
norm_ppd = np.trapz(ppdm,mgrid)

pad = np.array(padm)/norm_pad
ppd = np.array(ppdm)/norm_ppd

pad_med = np.array(padm_med)/norm_pad
ppd_med = np.array(ppdm_med)/norm_ppd

pad_lb = np.array(padm_lb)/norm_pad
ppd_lb = np.array(ppdm_lb)/norm_ppd

pad_ub = np.array(padm_ub)/norm_pad
ppd_ub = np.array(ppdm_ub)/norm_ppd

# save ppds

data_out = np.column_stack((mgrid, pad, pad_med, pad_lb, pad_ub, ppd, ppd_med, ppd_lb, ppd_ub))
header_out = 'm,mean,med,lb,ub,obs_mean,obs_med,obs_lb,obs_ub'

np.savetxt(out_path,data_out,header=header_out,comments='',delimiter=',')

# make diagnostic plot of ppds

dgn.ppd_plot(data_out,os.path.dirname(out_path)+'/ppd.png',ppd_type,True)
